{
  "_from": "tokepi@*",
  "_id": "tokepi@0.0.3",
  "_inBundle": false,
  "_integrity": "sha1-MLvam2H3tReC8262yulgS2FYU4M=",
  "_location": "/tokepi",
  "_phantomChildren": {},
  "_requested": {
    "type": "range",
    "registry": true,
    "raw": "tokepi@*",
    "name": "tokepi",
    "escapedName": "tokepi",
    "rawSpec": "*",
    "saveSpec": null,
    "fetchSpec": "*"
  },
  "_requiredBy": [
    "/emotional"
  ],
  "_resolved": "https://registry.npmjs.org/tokepi/-/tokepi-0.0.3.tgz",
  "_shasum": "30bbda9b61f7b51782f36eb6cae9604b61585383",
  "_spec": "tokepi@*",
  "_where": "/Users/tastizakarie/Downloads/code2040-hackathon/node_modules/emotional",
  "author": {
    "name": "Tim Coppieters",
    "email": "coppieters.tim@gmail.com"
  },
  "bugs": {
    "url": "https://github.com/ticup/tokepi/issues"
  },
  "bundleDependencies": false,
  "dependencies": {
    "emotional-emoticons": "*",
    "escape-regexp": "0.0.1",
    "underscore": "*",
    "underscore.string": "*"
  },
  "deprecated": false,
  "description": "Tokenizer that transforms a string of sentences into an array of white-space separated strings of tokens",
  "devDependencies": {
    "mocha": "*",
    "should": "*"
  },
  "engines": {
    "node": "*",
    "npm": "*"
  },
  "homepage": "https://github.com/ticup/tokepi#readme",
  "keywords": [
    "tokenize",
    "tokenizer",
    "tokens",
    "tokenizes",
    "tokenized",
    "sentences"
  ],
  "main": "index.js",
  "name": "tokepi",
  "optionalDependencies": {},
  "repository": {
    "type": "git",
    "url": "git+https://github.com/ticup/tokepi.git"
  },
  "scripts": {
    "test": "mocha"
  },
  "version": "0.0.3"
}
